\section{Results}
Things to show:
\begin{enumerate}
    \item Introduce datasets and metric(s)
    \begin{enumerate}
        \item Artificial dataset that breaks uniform sampling
        \item Benchmark dataset from ESA paper
        \item Geometric dataset that breaks lightweight coresets
    \end{enumerate}
    \item Running sensitivity sampling with kmeans++ does not scale with $k$ but fast-kmeans++ solution does
    \item Uniform sampling and lightweight coresets both don't work on simple toy datasets
    \item The size of the coreset seems to make a difference when performing sensitivity sampling but not as much
          when doing lightweight coreset and uniform
\end{enumerate}

\subsection{Experimental Setup}
\subsubsection{Metrics}

We analyze the coreset construction methods along two metrics -- quality and construction time.  Although measuring runtime is standard, predicting coreset
quality is a more difficult task. Specifically, it is unclear how to confirm that a subset of points satisfies the coreset property over all solutions. To this
end, the authors in \cite{chrisESA} suggested reporting the following metric 
\[ \max \left( \dfrac{\cost(P, \calC_{\Omega})}{\cost(\Omega, \calC_{\Omega})}, \dfrac{\cost(\Omega, \calC_{\Omega})}{\cost(P, \calC_{\Omega})} \right),\]
where $\calC_{\Omega}$ is a candidate solution that was computed over the coreset.

We refer to this metric as the \emph{coreset distortion}. Naturally, values that are consistently close to $1$ suggest that solutions on the coreset are likely
viable on the full dataset.

\input{figures/lightweight_breaks.tex}
\david{the lightweight corereset is also linear time, I removed the comment about running time of fast coreset. We need to reference somewhere this figure}

\subsubsection{Algorithms}
We compare our algorithm against 5 different benchmark algorithms. Ours is \emph{Fast-Coreset}~\ref{alg:main}, without the dimension-reduction step. The benchmarks are:
\begin{itemize}
        \item \emph{Standard uniform sampling}: choose a subset of $m \ll n$ points uniformly from $P$.
        \item \emph{Lightweight coreset}: find the mean $\mu$ of the dataset and obtain per-point sensitivity estimates by $\hat{s}(p) = 1/|P| + \cost(p, \mu) / \cost(P, \mu)$.
            The first term encourages uniform sampling while the second encourages sampling proportionate to the distance from the mean.
        \item \emph{Birch using Coresets (BICO)}: use BIRCH algorithm~\cite{birch} to create streaming coreset quickly. \david{could you say a bit more about this? At least, what's the running time and the theoretical guarantee?}
        \item \emph{Standard sensitivity sampling}: obtain an approximate $k$-means solution with $k$-means++ and sample a coreset proportionate to sensitivity as defined in \cref{eq:sensitivity}.
        \item \emph{Cut-$k$-means coreset}: for a given $j \in \{1,..., k\}$, find an approximate $j$-means solution with $j$-means++ algorithm, and sample a coreset proportionate to sensitivity as defined in \cref{eq:sensitivity}. We will try different values of $j$. 
%         $j = f(k)$ with $0 < f(k) < k$ for all $k$. We will sometimes use the notation
%            $f(k)$-means++ coreset when discussing a coreset built with respect to a specific function of $k$. For example, the $\log k$-means++ solution.
\end{itemize}
All but BICO have been implemented by us in a single codebase.

We take a moment here to motivate the Cut-$k$-means coreset algorithm.  Consider that lightweight coresets are simply solving $1$-means to obtain sensitivity values
whereas sensitivity sampling is solving the $k$-means problem. 
As lightweight coreset has the advantage of being fast, while sensitivity sampling is more precise, one could hope to interpolate in order to get the best of the two worlds: computing an approximate $j$-means solution may allow to obtain a more precise sampling distribution than that of lightweight-coreset, while being faster than sensitivity sampling.
% As we will show, it is easy to construct examples where lightweight coresets fail to produce
%acceptable coresets while sensitivity-sampling produces satisfactory coresets across datasets and settings. Thus, we study the $j$-means coreset
%algorithm to answer the following question: for which values of $j < k$ does an approximate $j$-means solution give a satisfactory coreset?

\subsubsection{Datasets}
\input{figures/coreset_size_on_quality.tex}

We employ several real and artificial datasets to evaluate the quality of a coreset. 

For our real-world data, we utilize the MNIST~\cite{mnist}, Song~\cite{song}, Census~\cite{census}, and Cover Type~\cite{covtype} datasets, whose characteristics are summarized in 
Table~\cref{tbl:datasets} below.
\begin{table}[htbp]
    \label{tbl:datasets}
    \centering
    \begin{tabular}{lrr}
        Dataset & Points & Dim \\
        \hline
        \emph{MNIST} & 60\,000 & 784 \\
        \emph{Song} & 515\,345 & 90 \\
        \emph{Cover Type} & 581\,012 & 54 \\
        \emph{Census} & 2\,458\,285 & 68
    \end{tabular}
    \caption{Description of real world datasets}
\end{table}

To complement those, we use several artificial datasets:
\begin{itemize}
    \item \emph{c-outlier}: $n-c$ points in a single location and $c$ points placed at a large distance away, for some constant $c$.
    \item \emph{Gaussian mixture}: multivariate Gaussians with varying cardinalities arranged randomly in high-dimensional space. \david{I think we should specify precisely what dimension, how many gaussians, with what covariance matrix}
    \item \emph{Geometric}: $n/2$ points at $(1, 0, 0, \cdots)$, $n/4$ points at $(0, 1, 0, \cdots)$, and so on. \david{I put the constant equal to $1$. What did you actually use?}
    \item \emph{Benchmark}: A specific distribution of points introduced in \cite{chrisESA} as a good testbed for coreset algorithms. 
    It has the property that all reasonable solutions are of equal quality but are maximally far
            apart in the solution space.
\end{itemize}

In all real and artificial datasets, we add random uniform noise $\eta$ with $0 \leq \eta_i \leq 0.001$ in each dimension in order to make all points unique.

\subsection{Algorithm Comparisons}
\label{ssec:alg_qualities}

We first compare Fast-Coreset with standard sensitivity sampling, both in terms of quality and runtime. 
%verify the fact that coreset quality is independent of whether we used $k$-means++ or \fkmeans to obtain the preliminary solution. 
To this end,
Figure~\ref{fig:coreset_size_on_sens_quality} shows that, across datasets, the Fast-Coreset method produces coresets of consistent quality, with all distortion
values being lower than $1.2$. 
Additionally, for sufficient coreset sizes ($m \approx 80\cdot k$), Fast-Coresets obtain similar distortion to those obtained
through sensitivity sampling. Despite this, Figure~\ref{fig:k_on_runtime} confirms that, while traditional sensitivity sampling runtime grows linearly with $k$,
Fast-Coreset only grow logarithmically with the number of centers. 
\david{question about this plot: what are $k$ and coreset size? It seems the legends says the first bar is for coreset size of $10k$, second one $50k$ etc. I think you told me that it is not what you did?}
 Therefore, our experimental findings confirm the theory predicted by \cref{thm:main}:
sensitivity sampling coresets can be implemented in linear time while preserving the coreset property. Given this context, we will not add traditional
sensitivity sampling to further experiments, as it is too slow to run on our large datasets and does not provide better quality results than the Fast-Coreset
method.

We now refer the reader to Figure~\ref{fig:coreset_size_on_quality}, where we show the effect of coreset size on the distortion across datasets and methods.  We
define the coreset sizes as $|\Omega| = ck$, where $c \in [20, 40, 60, 80]$. We see that, across datasets, coresets of larger size obtain lower distortion.
However, it is also clear that uniform, lightweight, and Cut-$k$-means coresets (with $j=\log k$) \david{Is this the right value of $j$?} all fail on the geometric-progression and Gaussian-mixture datasets. Additionally, uniform sampling expectedly fails on the $1$-outlier problem.
\david{I guess we have to comment the results for real-world and benchmark as well, which are not so good for us. It's hard to say with the resolution of those plots, but we have to comment: the aspect ratio is not that large, the clusters well balanced, so any lightweight and uniform may perform well}

As discussed, the sensitivities for lightweight coresets are obtained by a linear combination of a uniform distribution and each point's relative
distance to the mean. Since the Gaussian mixture dataset has randomly distributed clusters of varying sizes, a small cluster that is close to the mean is unlikely
to ever be sampled. We argue that, although this is a toy dataset, one can easily imagine real-world datasets that have this property. 
As a simple solution, we see
that the Cut-$k$-means coreset obtains satisfactory solutions on the Gaussian mixture dataset for 
\david{I don't know what you meant unfortunately}

A similar argument can be made for the more-challenging geometric dataset, where the cluster size decreases exponentially and all clusters are equidistant.
We show furthermore that, for small values of $j$, sensitivities obtained according to
solutions for $j$-means are insufficient to create a coreset for the geometric-progression dataset.

To measure further the effect that the class imbalance has on the quality of each coreset, we define a class imbalance parameter $\gamma$ and obtain each
cluster's size by $|C_i| = \frac{n}{m} \exp \left( \gamma(\rho - \frac{1}{2}) \right)$, where $\rho$ is distributed uniformly at random in the range $[0, 1]$.
Thus, each cluster has size $\frac{n}{m}$ when $\gamma = 0$ and the cluster size diverges exponentially as $\gamma$ grows linearly. We see the effect of $\gamma$ on the coreset
distortion in Table \textcolor{red}{Table ref}, where even small values of $\gamma$ can break the lightweight coreset construction. Looking at the
sensitivities computed via $j$-means++, we see that using $(j=\sqrt(k))$ maintains the coreset property for higher values of $\gamma$ but is still not guaranteed
to obtain satisfactory coresets. Despite this, sensitivity sampling consistently obtains coresets with low distortion. 
\david{So, this is a new dataset? Is it a variant of Geometric, or of Gaussian Mixture? I think it should be described in section 3.1.3. }

Lastly, we employ the \emph{Benchmark} dataset that  as a particularly challenging problem for coreset constructions.  The
benchmark dataset is  This naturally stress-tests
the sensitivity sampling approach, as every candidate solution's sensitivities are particularly difficult to approximate. \david{not sure we need to say more than in section 3.1.3 and in the paragraph explaining Figure~\ref{fig:coreset_size_on_quality}}

\input{figures/coreset_size_on_sens_quality.tex}
\input{figures/k_on_runtime.tex}
